# ğŸ¥ Palmo

ğŸ¬ [Watch our hackathon demo on YouTube]

![image](assets/MapPage.png)

## Table of Contents
- [Summary](#summary)
- [Motivation](#motivation)
- [Requirements](#requirements)
- [Tech Stack](#tech-stack)
- [Quick Start](#quick-start)
- [Features](#features)
- [API Endpoints](#api-endpoints)
- [Project Structure](#project-structure)
- [Contributors](#contributors)
- [Gallery](#gallery)

## Summary

"Palmo" is an interactive, gamified React web application designed to teach American Sign Language (ASL) through an engaging learning experience. The app features AI-powered sign recognition powered by OpenRouter API and Google's Gemini model, a curriculum-based lesson system, and game mechanics including coins, batteries, and streaks. Users progress through lessons on an interactive map, complete various challenge types, and can purchase items in the shop to enhance their learning journey. The application provides a smooth, animated user experience with Tailwind CSS styling.

âš ï¸ **Note**: Sign recognition features require a backend configured with OpenRouter API credentials and Gemini model access. The application will not function without proper AI service configuration.

## Motivation

Palmo was hacked in 24 hours during nwhacks 2026 to make sign language learning accessible, engaging, and fun through gamification. The project demonstrates proficiency in modern React development with TypeScript, AI integration for sign recognition, state management with Zustand, and building an interactive educational application. The app showcases skills in creating responsive user interfaces, implementing authentication flows, real-time camera-based sign detection, and creating an immersive learning experience with smooth animations and intuitive navigation.

## Requirements

- **Node.js** 18+ and npm
- **Backend API** configured with environment variables
- **OpenRouter API Key** - Required for AI-powered sign recognition (uses Google Gemini model)
- **Environment variables**: 
  - Frontend: `VITE_BACKEND_API_URL` and `VITE_BACKEND_WS_URL`
  - Backend: `OPEN_ROUTER_API_KEY`, `AI_ENDPOINT`, `AI_MODEL`
- **Camera access** (for sign recognition features)

âš ï¸ **Critical**: The sign recognition features will not work without OpenRouter API credentials configured in the backend.

## Tech Stack

- **Frontend**: React 19, React Router DOM, TypeScript
- **Styling**: Tailwind CSS, PostCSS
- **State Management**: Zustand
- **Authentication**: AWS Amplify, AWS Cognito
- **AI/ML**: OpenRouter API with Google Gemini model for sign language recognition
- **Build Tool**: Vite
- **Icons**: Lucide React
- **Backend Integration**: REST API and WebSocket for real-time sign recognition

## Quick Start

### Clone the repository:

```bash
git clone https://github.com/TeamEffectivo/frontend.git
cd frontend
```

### Environment Setup

âš ï¸ **Note**: This application requires backend API endpoints and environment variables to function properly. 

**Frontend environment variables** (`.env`):
```env
VITE_BACKEND_API_URL=your_backend_api_url
VITE_BACKEND_WS_URL=your_websocket_url
```

**Backend environment variables** (required for sign recognition):
```env
OPEN_ROUTER_API_KEY=your_openrouter_api_key
AI_MODEL=google/gemini-pro-vision
```

The backend uses OpenRouter API to access Google's Gemini model for AI-powered sign language recognition. Without these credentials, sign recognition features will not function.

### Installation and Development

Install dependencies:

```bash
npm install
```

Start the development server:

```bash
npm run dev
```

## Features

**User Authentication**: Sign up and sign in functionality with AWS Amplify. Users must be authenticated to access lessons and track progress.

**Interactive Map**: Navigate through lessons on a visually appealing map screen. Lessons are unlocked progressively as users complete challenges. The map features decorative elements like bushes and flowers, with smooth scrolling animations.

**Gamified Learning System**:
- **Coins**: Earn coins by completing challenges correctly (+5 coins per correct answer, +50 coins for completing a lesson)
- **Batteries**: Health system that decreases with incorrect answers
- **Streaks**: Build consecutive correct answer streaks for bonus rewards
- **Progress Tracking**: Lesson completion is saved locally and synced with backend

**Multiple Challenge Types**:
- **Tutorial**: Learn new signs with reference images and interactive practice
- **Sign Recognition**: Use camera to perform signs that are recognized by AI
- **Multiple Choice**: Select the correct answer from multiple options
- **Fill Blank**: Complete words or phrases by identifying missing letters

**AI-Powered Sign Recognition**: Real-time sign language recognition using camera input, powered by OpenRouter API and Google's Gemini Pro Vision model. The backend AI service processes images to identify ASL signs and letters. Supports both single image upload and WebSocket-based continuous recognition. This feature requires OpenRouter API credentials to function.

**Shop System**: Purchase items to enhance learning:
- **Streak Freeze**: Protects your streak for one day of inactivity (200 coins)
- **Battery Refill**: Restore health to continue learning (50 coins)

**Profile Management**: View and update user profile information, track learning statistics, and manage account settings.

**Calendar Screen**: Track learning activity and view progress over time.

**Letters Screen**: Browse and learn individual ASL letters with visual references.

**Responsive Design**: Fully responsive layout that works seamlessly on desktop, tablet, and mobile devices.

**Smooth Animations**: Engaging user experience with CSS transitions and animations for page transitions, component interactions, and feedback.

## API Endpoints

The application integrates with the following API endpoints (configured via `VITE_BACKEND_API_URL`):

### Authentication
- **AWS Amplify**: Handles user sign up, sign in, and session management

### User Management
- **GET** `/users/me` â†’ Fetch current user profile
- **PATCH** `/users/me` â†’ Update user profile information

### Sign Recognition
- **POST** `/extract-signs` â†’ Analyze a single image for sign recognition
- **WebSocket** `/ws/sign-language` â†’ Real-time continuous sign recognition via WebSocket

All API requests include:
- **Authorization**: `Bearer {JWT_TOKEN}` header (when user is authenticated)

## Project Structure

```
.
â”œâ”€â”€ public/                    # Static assets (images, GIFs, letter references)
â”‚   â”œâ”€â”€ letters/              # ASL letter reference images
â”‚   â””â”€â”€ *.gif                 # Animated mascot reactions
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ assets/               # Project-specific assets
â”‚   â”œâ”€â”€ Components/           # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ Bush.tsx         # Decorative bush component
â”‚   â”‚   â”œâ”€â”€ Flower.tsx       # Decorative flower component
â”‚   â”‚   â”œâ”€â”€ Palmo.tsx        # Mascot character component
â”‚   â”‚   â”œâ”€â”€ Reference.tsx    # Sign reference display component
â”‚   â”‚   â””â”€â”€ SideBar.tsx     # Navigation sidebar
â”‚   â”œâ”€â”€ data/                # Static data files
â”‚   â”‚   â”œâ”€â”€ curriculum.json  # Lesson curriculum structure
â”‚   â”‚   â””â”€â”€ dictionary.json  # Sign language dictionary
â”‚   â”œâ”€â”€ features/            # Feature screens and components
â”‚   â”‚   â”œâ”€â”€ AuthPage.tsx     # Authentication page
â”‚   â”‚   â”œâ”€â”€ CalendarScreen.tsx # Calendar view
â”‚   â”‚   â”œâ”€â”€ GameScreen.tsx   # Main lesson/game screen
â”‚   â”‚   â”œâ”€â”€ LettersScreen.tsx # Letters learning screen
â”‚   â”‚   â”œâ”€â”€ MapScreen.tsx    # Interactive lesson map
â”‚   â”‚   â”œâ”€â”€ Profile.tsx      # User profile page
â”‚   â”‚   â”œâ”€â”€ ShopScreen.tsx   # In-app shop
â”‚   â”‚   â””â”€â”€ gameplay/        # Game challenge components
â”‚   â”‚       â”œâ”€â”€ FillBlank.tsx
â”‚   â”‚       â”œâ”€â”€ MultipleChoice.tsx
â”‚   â”‚       â”œâ”€â”€ SignInterpreter.tsx # Camera-based sign recognition
â”‚   â”‚       â””â”€â”€ Sign.tsx
â”‚   â”œâ”€â”€ services/            # API and service integrations
â”‚   â”‚   â”œâ”€â”€ apiService.ts    # REST API service functions
â”‚   â”‚   â””â”€â”€ authService.ts   # Authentication service
â”‚   â”œâ”€â”€ store/               # State management
â”‚   â”‚   â””â”€â”€ useUserStore.ts  # Zustand store for user state (coins, batteries, streaks)
â”‚   â”œâ”€â”€ types/               # TypeScript type definitions
â”‚   â”‚   â”œâ”€â”€ index.ts
â”‚   â”‚   â””â”€â”€ user.ts
â”‚   â”œâ”€â”€ App.tsx              # Main app component with routing
â”‚   â”œâ”€â”€ EnvConfig.ts         # Environment configuration
â”‚   â”œâ”€â”€ index.css            # Global styles
â”‚   â””â”€â”€ main.tsx             # React DOM render entry
â”œâ”€â”€ eslint.config.js         # ESLint configuration
â”œâ”€â”€ index.html
â”œâ”€â”€ package.json
â”œâ”€â”€ postcss.config.js        # PostCSS configuration
â”œâ”€â”€ tailwind.config.js       # Tailwind CSS configuration
â”œâ”€â”€ tsconfig.json            # TypeScript configuration
â”œâ”€â”€ tsconfig.app.json        # TypeScript app configuration
â”œâ”€â”€ tsconfig.node.json       # TypeScript node configuration
â”œâ”€â”€ vite.config.ts           # Vite build configuration
â””â”€â”€ README.md
```

## Contributors

- Daylen Smith
- Elena Jou
- Irene Cheung
- Calvin Che

## Gallery
![image](assets/LettersPage.png)
![image](assets/CalendarPage.png)
![image](assets/ShopPage.png)